{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alternative-payroll",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-north",
   "metadata": {},
   "source": [
    "* In this notebook we are going to classify dog-cat and pandas images. KNN(k-Nearest Neighbors Algorithm) is not a deep learning algoritm, and actually it is not learn anything. But it is really easy to understand and not requires lots of energy to implement. So, lets start."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "palestinian-communications",
   "metadata": {},
   "source": [
    "##### To get able to use this notebook,you have to download all images dataset. Of course you can use your private cat-dog-panda images too, but be sure that your images file format is i.e for cats should like this: cats_00001.jpg, cats_00002.jpg ....\n",
    "\n",
    "##### and folder format is:\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "##### If not, you probably can not use codes in this notebook without making changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-humidity",
   "metadata": {},
   "source": [
    "### Dataset is here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-shooting",
   "metadata": {},
   "source": [
    "## Basic Image Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "steady-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "class SimplePreprocessor:\n",
    "    def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
    "        #store the target image width, height and interpolation\n",
    "        #method used when resizing\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.inter = inter\n",
    "        \n",
    "    def preprocess(self, image):\n",
    "         #resize the image to a fixed size, igroring the aspect\n",
    "         # ration\n",
    "        return cv2.resize(image, (self.width, self.height),\n",
    "                         interpolation=self.inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-settle",
   "metadata": {},
   "source": [
    "## Building Image Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hispanic-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class SimpleDatasetLoader:\n",
    "    def __init__(self, preprocessors=None):\n",
    "        # store the image preprocessor\n",
    "        self.preprocessors = preprocessors\n",
    "        \n",
    "        # if the preprocessors are None, initialize them\n",
    "        # as an empty list\n",
    "        if self.preprocessors is None:\n",
    "            self.preprocessors = []\n",
    "    \n",
    "    def load(self, imagePaths, verbose=-1):\n",
    "        # initialize the list of features and labels\n",
    "        data = []\n",
    "        labels = []\n",
    "        \n",
    "        # loop over the input images\n",
    "        for (i, imagePath) in enumerate(imagePaths):\n",
    "            # load the image and extract the class label assuming\n",
    "            # that our path has the following format:\n",
    "            # /path/to/dataset/{class}/{image}.jpg\n",
    "            image = cv2.imread(imagePath)\n",
    "            label = imagePath.split(os.path.sep)[-2]\n",
    "            \n",
    "            # check to see if our preprocessors are not None\n",
    "            if self.preprocessors is not None:\n",
    "                # loop over the preprocessors and apply each to\n",
    "                # the image\n",
    "                for p in self.preprocessors:\n",
    "                    image = p.preprocess(image)\n",
    "            \n",
    "            # treat our processed image as a \"feature vector\"\n",
    "            # by updating the data list followed by the labels\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "            \n",
    "            # show an update every 'verbose' images\n",
    "            if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
    "                print(\"[INFO] processed {}/{}\".format(i + 1,\n",
    "                     len(imagePath)))\n",
    "        #return a tuple of the data and labels\n",
    "        return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-yesterday",
   "metadata": {},
   "source": [
    "## k-NN: A Simple Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-heater",
   "metadata": {},
   "source": [
    "* The k-Nearest Neighbor classifier is by far the most simple machine learning and image classification algorithm.\n",
    "In fact, it’s so simple that it doesn’t actually “learn” anything. Instead, this algorithm directly relies on the distance between feature vectors (which in our case, are the raw\n",
    "RGB pixel intensities of the images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attached-essay",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] processed 500/81\n",
      "[INFO] processed 1000/81\n",
      "[INFO] processed 1500/81\n",
      "[INFO] processed 2000/81\n",
      "[INFO] processed 2500/83\n",
      "[INFO] processed 3000/83\n",
      "[INFO] features matrix: 9.0MB\n",
      "[INFO] evaluating k-NN classifier...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.39      0.56      0.46       262\n",
      "        dogs       0.40      0.46      0.43       249\n",
      "       panda       0.92      0.32      0.48       239\n",
      "\n",
      "    accuracy                           0.45       750\n",
      "   macro avg       0.57      0.45      0.45       750\n",
      "weighted avg       0.56      0.45      0.45       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "\n",
    "\n",
    "# grab the list of images that we’ll be describing\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(\"/media/data/E81A6D761A6D4324/UBUNTU 20.04/Ai/datasets/animals/\"))\n",
    "\n",
    "# initialize the image preprocessor, load the dataset from disk,\n",
    "# and reshape the data matrix\n",
    "sp = SimplePreprocessor(32, 32)\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.reshape((data.shape[0], 3072))\n",
    "\n",
    "# show some information on memory consumption of the images\n",
    "print(\"[INFO] features matrix: {:.1f}MB\".format(\n",
    "data.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "# encode the labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "    test_size=0.25, random_state=42)\n",
    "\n",
    "# train and evaluate a k-NN classifier on the raw pixel intensities\n",
    "print(\"[INFO] evaluating k-NN classifier...\")\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(trainX, trainY)\n",
    "print(classification_report(testY, model.predict(testX),\n",
    "    target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-logistics",
   "metadata": {},
   "source": [
    "* This notebook based on Adrian Rosebrock's Deep Learning for Computer Vision with Python - Starter Bundle book.To more information please visit his website (https://www.pyimagesearch.com/ ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_image",
   "language": "python",
   "name": "env_image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
